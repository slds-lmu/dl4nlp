<!DOCTYPE html>
<html><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="/dl4nlp/css/style.css">


<title>Deep Learning for Natural Language Processing (DL4NLP) | Chapter 6: Post-BERT Era 2 and using the Transformer </title>


<link rel="apple-touch-icon" sizes="180x180" href="/dl4nlp/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/dl4nlp/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/dl4nlp/favicon-16x16.png">
<link rel="manifest" href="/dl4nlp/site.webmanifest">
<link rel="mask-icon" href="/dl4nlp/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">

</head><body>
<img id="logo" src="/dl4nlp/dl4nlp.svg" />

<div id="nav-border" class="container">
    <nav id="nav" class="nav justify-content-center">
        
        <a class="nav-link" href="/dl4nlp">
        
        Home
        </a>
        
        <a class="nav-link" href="/dl4nlp/chapters/">
        
        Chapters
        </a>
        
        <a class="nav-link" href="/dl4nlp/appendix/">
        
        Appendix
        </a>
        
        <a class="nav-link" href="/dl4nlp/exercises/">
        
        Exercises
        </a>
        
        <a class="nav-link" href="/dl4nlp/references/">
        
        References
        </a>
        
        <a class="nav-link" href="/dl4nlp/team/">
        
        Team
        </a>
        
    </nav>
</div><div id="content" class="container">
<h1>Chapter 6: Post-BERT Era 2 and using the Transformer </h1>

<p><p>Here we further introduce models from the Post-BERT era, such as ELECTRA and XLNet. We also discuss how we can reformulate every task into a text-to-text format and finally introduce the T5 model.</p>
</p>


<div class="chapter_overview">
<ul class="list-unstyled">


<li>
    <a class="title" href="/dl4nlp/chapters/06_post_bert_t5/06_01_postbert/">Chapter 6.1: Post-BERT architectures</a>
    
      
        <p>This chapter will introduce two new architectures from the post-BERT era, namely ELECTRA and XLNet. By changing the pre training approach we can create new models.
</p>
      
      
</li>

<li>
    <a class="title" href="/dl4nlp/chapters/06_post_bert_t5/06_02_text2text/">Chapter 6.2: Tasks as text-to-text problem</a>
    
      
        <p>BERT has many shortcomings which is why we reformulate every classification task as a text-to-text problem.
</p>
      
      
</li>

<li>
    <a class="title" href="/dl4nlp/chapters/06_post_bert_t5/06_03_t5/">Chapter 6.3: BERT-based architectures</a>
    
      
        <p>Here we introduce T5 (Text-To-Text Transfer Transformer) a complete encoder-decoder Transformer architecture, which reformulates every task as text-to-text tasks.
</p>
      
      
</li>


</ul>
</div>


        </div><footer class="bg-light text-center text-lg-start fixed-bottom">
<ul class="list-inline text-center">
  <li class="list-inline-item">Â© 2022 Course Creator</li>
  
  <li class="list-inline-item"><a class="nav-link" href="https://slds-lmu.github.io/i2ml/" target="_blank">I2ML Course</a></li>
  
  <li class="list-inline-item"><a class="nav-link" href="https://github.com/slds-lmu/lecture_dl4nlp" target="_blank">Material Source Code</a></li>
  
  <li class="list-inline-item"><a class="nav-link" href="https://github.com/slds-lmu/dl4nlp" target="_blank">Website source code</a></li>
  
</ul>
</footer>



</body>
</html>
