<!DOCTYPE html>
<html><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="/dl4nlp/css/style.css">


<title>Deep Learning for Natural Language Processing (DL4NLP) | Chapter 3: Transformer</title>


<link rel="apple-touch-icon" sizes="180x180" href="/dl4nlp/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/dl4nlp/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/dl4nlp/favicon-16x16.png">
<link rel="manifest" href="/dl4nlp/site.webmanifest">
<link rel="mask-icon" href="/dl4nlp/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">

</head><body>
<img id="logo" src="/dl4nlp/dl4nlp.svg" />

<div id="nav-border" class="container">
    <nav id="nav" class="nav justify-content-center">
        
        <a class="nav-link" href="/dl4nlp">
        
        Home
        </a>
        
        <a class="nav-link" href="/dl4nlp/chapters/">
        
        Chapters
        </a>
        
        <a class="nav-link" href="/dl4nlp/appendix/">
        
        Appendix
        </a>
        
        <a class="nav-link" href="/dl4nlp/exercises/">
        
        Exercises
        </a>
        
        <a class="nav-link" href="/dl4nlp/references/">
        
        References
        </a>
        
        <a class="nav-link" href="/dl4nlp/team/">
        
        Team
        </a>
        
    </nav>
</div><div id="content" class="container">
<h1>Chapter 3: Transformer</h1>

<p><p>The Transformer, as introduced in [1], is a deep learning model architecture specifically designed for sequence-to-sequence tasks in natural language processing. It revolutionizes NLP by replacing recurrent layers with self-attention mechanisms, enabling it to process entire sequences in parallel, overcoming the limitations of sequential processing in traditional RNN-based models like LSTMs. This architecture has become the foundation for state-of-the-art models in various NLP tasks such as machine translation, text summarization, and language understanding. In this chapter we first introduce the transformer, explore different parts of it (Encoder and Decoder) and finally discuss ways to improve the architecture, such as Transformer-XL and Efficient Transformers.</p>
<h3 id="references">References</h3>
<ul>
<li>[1] <a href="https://arxiv.org/abs/1706.03762">Vaswani et al., 2017</a></li>
</ul>
<h3 id="additional-resources">Additional Resources</h3>
<ul>
<li><a href="https://www.youtube.com/watch?v=bCz4OMemCcA&amp;t">Very good video explaining the Transformer and Attention</a></li>
<li><a href="https://www.youtube.com/watch?v=wjZofJX0v4M&amp;t">3Blue1Brown Videoseries about the Transformer</a></li>
</ul></p>


<div class="chapter_overview">
<ul class="list-unstyled">


<li>
    <a class="title" href="/dl4nlp/chapters/03_transformer/03_01_intro_trafo/">Chapter 03.01: A universal deep learning architecture</a>
    
      
        <p>Transformers have been adapted and applied to various domains and tasks in addition to traditional sequence-to-sequence tasks in NLP. This chapter mentions a few examples of models that apply the transformer architecture to various domains. Examples include: Vision Transformer (ViT) [1]: Utilizes transformer architecture for image classification tasks, demonstrating competitive performance compared to convolutional neural networks (CNNs). CLIP [2]: A model that connects images and text through a unified embedding space, enabling tasks such as zero-shot image classification and image-text retrieval.
</p>
      
      
</li>

<li>
    <a class="title" href="/dl4nlp/chapters/03_transformer/03_02_encoder/">Chapter 03.02: The Encoder</a>
    
      
        <p>The Encoder in a transformer model is responsible for processing the input sequence and generating contextualized representations of each token, capturing both local and global dependencies within the sequence. It achieves this by employing self-attention mechanisms, which allow each token to attend to all other tokens in the input sequence, enabling the model to capture relationships and dependencies between tokens regardless of their positions. Additionally, the encoder includes position-wise feedforward networks to further refine the representations and incorporate positional information.
</p>
      
      
</li>

<li>
    <a class="title" href="/dl4nlp/chapters/03_transformer/03_03_decoder/">Chapter 03.03: The Decoder</a>
    
      
        <p>The Decoder in a transformer model is responsible for generating an output sequence based on the contextualized representations generated by the encoder, facilitating tasks such as sequence generation and machine translation. It achieves this by utilizing self-attention mechanisms, similar to the encoder, to capture dependencies within the input sequence and cross-attention mechanisms to attend to the Encoder-output, enabling the model to focus on relevant parts of the input during decoding. Additionally, the decoder includes position-wise feedforward networks to further refine the representations and generate the output sequence token by token.
</p>
      
      
</li>

<li>
    <a class="title" href="/dl4nlp/chapters/03_transformer/03_04_trafo_xl/">Chapter 03.04: Long Sequences: Transformer-XL</a>
    
      
        <p>This chapter is about the Transformer-XL [1] and how it deals with the issue of long sequences. Transformer-XL is an extension of the original Transformer architecture designed to address the limitations of long-range dependency modeling in sequence-to-sequence tasks. It aims to solve the problem of capturing and retaining information over long sequences by introducing a segment-level recurrence mechanism, enabling the model to process sequences of arbitrary length without being constrained by fixed-length contexts or running into computational limitations. Additionally, Transformer-XL incorporates relative positional embeddings to better capture positional information across segments of varying lengths.
</p>
      
      
</li>

<li>
    <a class="title" href="/dl4nlp/chapters/03_transformer/03_05_efficient/">Chapter 03.05: Efficient Transformers</a>
    
      
        <p>Efficient Transformers are designed to mitigate the computational and memory requirements of standard transformer architectures, particularly when dealing with large-scale datasets or resource-constrained environments. They aim to address issues such as scalability and efficiency in training and inference. One approach used in efficient transformers is replacing the standard self-attention mechanism with more lightweight attention mechanisms, which reduce the computational complexity of attending to long sequences by approximating the attention mechanism with lower-rank matrices or restricting attention to local or sparse regions of the sequence. These approaches enable transformers to be more practical for real-world applications where computational resources are limited.
</p>
      
      
</li>


</ul>
</div>


        </div><footer class="bg-light text-center text-lg-start fixed-bottom">
<ul class="list-inline text-center">
  <li class="list-inline-item">Â© 2022 Course Creator</li>
  
  <li class="list-inline-item"><a class="nav-link" href="https://slds-lmu.github.io/i2ml/" target="_blank">I2ML Course</a></li>
  
  <li class="list-inline-item"><a class="nav-link" href="https://github.com/slds-lmu/lecture_dl4nlp" target="_blank">Material Source Code</a></li>
  
  <li class="list-inline-item"><a class="nav-link" href="https://github.com/slds-lmu/dl4nlp" target="_blank">Website source code</a></li>
  
</ul>
</footer>



</body>
</html>
