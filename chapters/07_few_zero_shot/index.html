<!DOCTYPE html>
<html><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="/dl4nlp/css/style.css">


<title>Deep Learning for Natural Language Processing (DL4NLP) | Chapter 7: Few-/Zero-Shot Learning &amp; Prompting</title>


<link rel="apple-touch-icon" sizes="180x180" href="/dl4nlp/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/dl4nlp/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/dl4nlp/favicon-16x16.png">
<link rel="manifest" href="/dl4nlp/site.webmanifest">
<link rel="mask-icon" href="/dl4nlp/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">

</head><body>
<img id="logo" src="/dl4nlp/dl4nlp.svg" />

<div id="nav-border" class="container">
    <nav id="nav" class="nav justify-content-center">
        
        <a class="nav-link" href="/dl4nlp">
        
        Home
        </a>
        
        <a class="nav-link" href="/dl4nlp/chapters/">
        
        Chapters
        </a>
        
        <a class="nav-link" href="/dl4nlp/appendix/">
        
        Appendix
        </a>
        
        <a class="nav-link" href="/dl4nlp/exercises/">
        
        Exercises
        </a>
        
        <a class="nav-link" href="/dl4nlp/references/">
        
        References
        </a>
        
        <a class="nav-link" href="/dl4nlp/team/">
        
        Team
        </a>
        
    </nav>
</div><div id="content" class="container">
<h1>Chapter 7: Few-/Zero-Shot Learning &amp; Prompting</h1>

<p><p>A concurring paradigm to the pretrain/finetune procedure, which most of the previously introduced architectures are subject to, is few- and zero-shot learning.
In this paradigm, a (large!) pre-trained architecture is <em>not</em> fine-tuned to specific task, but prompted with a task description and a few labeled examples (or
none, in case of zero-shot) in order to predict the correct label for an instance simply due to its capabilites gained during pre-training.</p>
</p>


<div class="chapter_overview">
<ul class="list-unstyled">


<li>
    <a class="title" href="/dl4nlp/chapters/07_few_zero_shot/07_01_bertproblems/">Chapter 7.1: Problems with BERT</a>
    
      
        <p>We investigate some problems of encoder-based transformer models, such as BERT, to understand what GPT-3 attempts to solve.
</p>
      
      
</li>

<li>
    <a class="title" href="/dl4nlp/chapters/07_few_zero_shot/07_02_gptxshot/">Chapter 7.2: Intro to GPT and X-shot learning</a>
    
      
        <p>In this chapter we introduce GPT and see how GPT makes predictions.
</p>
      
      
</li>

<li>
    <a class="title" href="/dl4nlp/chapters/07_few_zero_shot/07_03_tasks/">Chapter 7.3: GPT Performance</a>
    
      
        <p>Given GPT&amp;rsquo;s zero- and few-shot abilities, it can be used to tackle many tasks. We present an investigation of its perfomance on various types of tasks.
</p>
      
      
</li>

<li>
    <a class="title" href="/dl4nlp/chapters/07_few_zero_shot/07_041_limitations/">Chapter 7.4.1: GPT limitations</a>
    
      
        <p>This chapter investigates various issues GPT has. This includes specific tasks and a comparison to human learning.
</p>
      
      
</li>

<li>
    <a class="title" href="/dl4nlp/chapters/07_few_zero_shot/07_042_limitations_historyhype/">Chapter 7.4.2: Hype</a>
    
      
        <p>GPT-3 created a huge hype around it. In this chapter we look at a different angles of this hype.
</p>
      
      
</li>

<li>
    <a class="title" href="/dl4nlp/chapters/07_few_zero_shot/07_043_limitations_marcusdavid/">Chapter 7.4.3: Marcus &amp; David</a>
    
      
        <p>Marcus &amp;amp; Davis look at multiple types of reasoning and analyze how GPT-3 deals with it.
</p>
      
      
</li>

<li>
    <a class="title" href="/dl4nlp/chapters/07_few_zero_shot/07_05_discussion/">Chapter 7.5: Discussion</a>
    
      
        <p>In this final chapter, we discuss ethical considerations and the cost of GPT-3.
</p>
      
      
</li>


</ul>
</div>


        </div><footer class="bg-light text-center text-lg-start fixed-bottom">
<ul class="list-inline text-center">
  <li class="list-inline-item">Â© 2022 Course Creator</li>
  
  <li class="list-inline-item"><a class="nav-link" href="https://slds-lmu.github.io/i2ml/" target="_blank">I2ML Course</a></li>
  
  <li class="list-inline-item"><a class="nav-link" href="https://github.com/slds-lmu/lecture_dl4nlp" target="_blank">Material Source Code</a></li>
  
  <li class="list-inline-item"><a class="nav-link" href="https://github.com/slds-lmu/dl4nlp" target="_blank">Website source code</a></li>
  
</ul>
</footer>



</body>
</html>
