<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Chapter 2: Deep Learning Basics on Deep Learning for Natural Language Processing (DL4NLP)</title><link>https://slds-lmu.github.io/dl4nlp/chapters/02_dl_basics/</link><description>Recent content in Chapter 2: Deep Learning Basics on Deep Learning for Natural Language Processing (DL4NLP)</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://slds-lmu.github.io/dl4nlp/chapters/02_dl_basics/index.xml" rel="self" type="application/rss+xml"/><item><title>Chapter 02.01: Recurrent Neural Networks</title><link>https://slds-lmu.github.io/dl4nlp/chapters/02_dl_basics/02_01_rnn/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://slds-lmu.github.io/dl4nlp/chapters/02_dl_basics/02_01_rnn/</guid><description>&lt;p>This chapter introduces Recurrent Neural Networks in the context of Language Modelling and discusses different types of RNNs, such as LSTMs and Bidirectional RNNs.&lt;/p></description></item><item><title>Chapter 02.02 Attention</title><link>https://slds-lmu.github.io/dl4nlp/chapters/02_dl_basics/02_02_attention/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://slds-lmu.github.io/dl4nlp/chapters/02_dl_basics/02_02_attention/</guid><description>&lt;p>This chapter provides a first introduction to the Attention mechanism as a way to model long range dependencies.&lt;/p></description></item><item><title>Chapter 02.03: ELMo</title><link>https://slds-lmu.github.io/dl4nlp/chapters/02_dl_basics/02_03_elmo/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://slds-lmu.github.io/dl4nlp/chapters/02_dl_basics/02_03_elmo/</guid><description>&lt;p>In this chapter we introduce ELMo, a modelling approach, that enables us to contextualize word embeddings.&lt;/p></description></item><item><title>Chapter 02.04 Revisiting words: Tokenization</title><link>https://slds-lmu.github.io/dl4nlp/chapters/02_dl_basics/02_04_tokenization/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://slds-lmu.github.io/dl4nlp/chapters/02_dl_basics/02_04_tokenization/</guid><description>&lt;p>In order to feed text data into a model we have to tokenize it first. This chapter discusses various types of text tokenization.&lt;/p></description></item></channel></rss>