---
title: "Chapter 2.1: Loss Functions for Regression"
quizdown: true
---
L1 and L2 are two essential loss functions used for evaluating the performance of regression models. This section defines L1 and L2 loss and explains the differences.

<!--more-->
{{< video id="Syrzezpj2FY" >}}

{{< pdfjs file="https://github.com/slds-lmu/lecture_i2ml/blob/master/slides-pdf/slides-regression-losses.pdf" >}}

{{< quizdown >}}

---
shuffle_questions: false
---

## Human verification

What picture shows an apple?

- [x] ![](https://upload.wikimedia.org/wikipedia/commons/2/22/Malus_domestica_a1.jpg)
- [x] ![](https://upload.wikimedia.org/wikipedia/commons/9/92/95apple.jpeg)
- [x] ![](https://upload.wikimedia.org/wikipedia/commons/thumb/e/e3/Macintosh_128k_transparency.png/511px-Macintosh_128k_transparency.png)
- [ ] ![]({{< fileurl file="Bananas.svg" >}})

## Loss Functions

Which statements are true?

---
shuffle_answers: true
---

- [ ] The absolute loss function is more sensitive to outliers than the quadratic loss function.
- [x] Optimization of $L2$ loss is easier than of $L1$ loss.

## Linear Regression

Which statements are true?

---
shuffle_answers: true
---

- [x] The target in linear regression has to be numeric
- [ ] The features in linear regression have to be numeric
- [x] The classical linear model from statistics with gaussian errors is linear regression with $L2$-loss
- [x] The hypothesis space of linear regression consists of linear functions of the features

{{< /quizdown >}}


