---
title: "Chapter 5: Transformer"
---
This chapter introduces a novel type of neural network architecture which nowadays is used as the backbone of nearly all state-of-the-art NLP models. It has nearly entirely replaced recurrent networks as the workhorse of the whole field and is currently very well on track to do the same to convolutional nets in Computer Vision as well.

<!--more-->

### References 

- [Vaswani et al. (2017)](https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)
- [Great talk by Lukasz Kaiser](https://www.youtube.com/watch?v=rBCqOTEfxvg)
- [The Annotated Transformer](https://nlp.seas.harvard.edu/2018/04/03/attention.html)
