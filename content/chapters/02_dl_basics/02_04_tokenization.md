---
title: "Chapter 02.04 Revisiting words: Tokenization"
weight: 2004
---
In order to feed text data into a model we have to tokenize it first. This chapter discusses various types of text tokenization.

<!--more-->

### Lecture slides

{{< pdfjs file="https://github.com/slds-lmu/lecture_dl4nlp/blob/main/slides/chapter02-deeplearningbasics/slides-24-tokenization.pdf" >}}
