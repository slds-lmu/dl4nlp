---
title: "Chapter 6.4.3: Encoder-Decoder architectures"
weight: 6043
---
This chapter will cover a set of models using the whole transformer architecture again.
(_Note: T0 still to be added in future_)

<!--more-->

<!--
### Lecture video
{{< video id="TfrSKiOecWI" >}}
{{< pdfjs file="https://github.com/slds-lmu/lecture_dl4nlp/blob/main/slides/chapter6-usingtrafo/slides-647-t0.pdf" >}}
-->

### Lecture Slides
{{< pdfjs file="https://github.com/slds-lmu/lecture_dl4nlp/blob/main/slides/chapter6-usingtrafo/slides-646-t5.pdf" >}}  

### References 

- [Raffel et al. (2019)](https://arxiv.org/pdf/1910.10683.pdf)
- [Sanh et al. (2022)](https://openreview.net/pdf?id=9Vrb9D0WI4)
