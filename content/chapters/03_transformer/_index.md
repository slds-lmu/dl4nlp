---
title: "Chapter 3: Transformer"
---
The Transformer, as introduced in [1], is a deep learning model architecture specifically designed for sequence-to-sequence tasks in natural language processing. It revolutionizes NLP by replacing recurrent layers with self-attention mechanisms, enabling it to process entire sequences in parallel, overcoming the limitations of sequential processing in traditional RNN-based models like LSTMs. This architecture has become the foundation for state-of-the-art models in various NLP tasks such as machine translation, text summarization, and language understanding. In this chapter we first introduce the transformer, explore different parts of it (Encoder and Decoder) and finally discuss ways to improve the architecture, such as Transformer-XL and Efficient Transformers.

<!--more-->

### References 

- [1] [Vaswani et al., 2017](https://arxiv.org/abs/1706.03762)   

### Additional Resources 

- [Very good video explaining the Transformer and Attention](https://www.youtube.com/watch?v=bCz4OMemCcA&t)
- [3Blue1Brown Videoseries about the Transformer](https://www.youtube.com/watch?v=wjZofJX0v4M&t) 
