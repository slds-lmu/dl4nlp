---
title: "Chapter 03.01: A universal deep learning architecture"
weight: 3001
---
Transformers have been adapted and applied to various domains and tasks in addition to traditional sequence-to-sequence tasks in NLP. This chapter mentions a few examples of models that apply the transformer architecture to various domains. 
Examples include: Vision Transformer (ViT) [1]: Utilizes transformer architecture for image classification tasks, demonstrating competitive performance compared to convolutional neural networks (CNNs). CLIP [2]: A model that connects images and text through a unified embedding space, enabling tasks such as zero-shot image classification and image-text retrieval.


<!--more-->

<!--
### Lecture video
{{< video id="TfrSKiOecWI" >}}
-->

### Lecture Slides
{{< pdfjs file="https://github.com/slds-lmu/lecture_dl4nlp/blob/main/slides/chapter03-transformer/slides-31-intro-trafo.pdf" >}}

### References 

- [1] [Dosovitskiy et al., 2021](https://arxiv.org/abs/2010.11929)
- [2] [Radford et al., 2021](https://arxiv.org/abs/2103.00020)



