---
title: "Chapter 4.3.2: ULMFiT"
weight: 4032
---
In contrast to ELMo, this architecture is not able to produce bidirectionally contextual embeddings but only unidirectionally contextual ones (since unidirectional LSTM are employed). Apart from this, is relies on a different transfer learning paradigm. Instead of "only" generating embedding which can be used for downstream tasks, the whole architecture is _fine-tuned_ towards a specific task. Hence the name *U*niversal *L*anguage *M*odel *Fi*ne-*T*uning (ULMFiT).

<!--more-->

<!--
### Lecture video
{{< video id="TfrSKiOecWI" >}}
-->

### Lecture Slides
{{< pdfjs file="https://github.com/slds-lmu/lecture_dl4nlp/blob/main/slides/chapter4-transferlearning/slides-432-ulmfit.pdf" >}}

### References 

- [Howard \& Ruder, 2018](https://arxiv.org/pdf/1801.06146.pdf)
- [Merity et al., 2017](https://arxiv.org/pdf/1708.02182.pdf)
