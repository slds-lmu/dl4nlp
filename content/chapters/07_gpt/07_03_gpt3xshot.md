---
title: "Chapter 07.03: GPT-3 (2020) & X-shot learning"
weight: 7003
---
In this chapter, we'll explore GPT-3 [1]. GPT-3 builds on the successes of its predecessors, boasting a massive architecture and extensive pre-training on diverse text data. Unlike previous models, GPT-3 introduces a few-shot learning approach, allowing it to perform tasks with minimal task-specific training data. With its remarkable scale and versatility, GPT-3 represents a significant advancement in natural language processing, showcasing the potential of large-scale transformer architectures in various applications. 

<!--more-->
### Lecture Slides

{{< pdfjs file="https://github.com/slds-lmu/lecture_dl4nlp/blob/main/slides/chapter07-gpt/slides-73-gpt3xshot.pdf" >}}

### References 

- [1] [Brown et al., 2020](https://arxiv.org/abs/2005.14165)
